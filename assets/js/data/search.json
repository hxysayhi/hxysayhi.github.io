[ { "title": "如何临时或永久修改route table", "url": "/posts/b9ec2c19/", "categories": "Technology, notes", "tags": "writing, IT, Linux, route", "date": "2023-06-30 08:34:50 +0800", "snippet": "内容摘要如何修改route table，如何临时增加或删除路由条目，如何永久添加或删除路由条目。主要涉及route命令、nmcli命令、相关配置文件持久化位置等临时修改，重启后丢失直接使用 route 命令可以进行临时修改，但是在系统重启或者是执行interface的重启后会丢失。命令使用方式：route {add | delete} {-host | -net} {des_ip} [netmask {net mask}] [gw {gw}] [dev {device}]route add：命令关键字，表示增加路由，若要删除路由，则为route del；-host | -net：表示路由目标是主机还是网段；netmask：表示路由目标为网段时才会使用到，表示路由目标网段的子网掩码；gw：命令关键字，后面跟下一跳网关；dev：命令关键字，后面跟具体设备名，表示路由是从该设备出去。metric：为路由指定所需跳数里的多个路由中选择与转发包中的目标地址最为匹配的路由。所选的路由具有最少的跳数。跳数能够反映途经节点的数量、路径的速度、路径可靠性、路径吞吐量以及管理属性。示例：添加路由：route add –host 192.168.168.110 dev eth0route add –host 192.168.168.119 gw 192.168.168.1route add -net 192.168.3.0/24 dev eth0route add -net 192.168.2.0/24 gw 192.168.2.254route add –net 180.200.0.0 netmask 255.255.0.0 gw 10.200.6.201 dev eth0 metric 1添加默认网关：route add default gw 99.12.11.253删除路由：route del –host 192.168.168.110 dev eth0通过 nmcli 修改通过 nmcli 修改配置，可以永久保存，在系统重启后，该配置仍有效。nmcli connection show 找到要添加的route的设备对应的connection名。执行修改：nmcli connection modify “connection-name” +ipv4.routes “network address/prefix gateway”nmcli connection up “connection-name”至此，就已经完成了 route 的添加，此时通过 route -n 可以查看到添加后的route 表。注意 +ipv4.routes 中的 + 表示添加，如果没有 + 则表示覆盖，如果需要移除，则使用 - ,即 -ipv4.routes。以上命令举报幂等性，可以重复执行。其中 nmcli connection modify “connection-name” +ipv4.routes “network address/prefix gateway” 执行后，会在文件系统中将配置持久化。持久化的位置可以通过 nmcli -f NAME,DEVICE,FILENAME connection show 查看：NAME DEVICE FILENAMEbridge-br0 br0 /etc/sysconfig/network-scripts/ifcfg-bridge-br0virbr0 virbr0 /run/NetworkManager/system-connections/virbr0.nmconnectionbridge-slave-eno1 eno1 /etc/sysconfig/network-scripts/ifcfg-bridge-slave-eno1vnet1 vnet1 /run/NetworkManager/system-connections/vnet1.nmconnectioneno2 -- /etc/sysconfig/network-scripts/ifcfg-eno2通过上述命令可能不能准确地找到每个 device 全部的配置文件，但是基本可以定位配置文件存放的目录。如果通过nmcli修改的内容是添加 route 表，在红帽和ubuntu中配置文件存放的位置如下：rhel 中，位于： /etc/sysconfig/network-scripts/route-{name_of_connection}ubuntu 中，位于: /etc/NetworkManager/system-connections/{name_of_connection}.nmconnection直接修改配置文件知道了配置存储的位置，我们可以直接在通过添加、修改配置文件的方式，来实现永久添加route 的目的。但是在不同的系统中，由于管理工具差异，配置文件有所不同。以 rhel为例：如果 network connection 是 enp0s3, 那么配置文件的名字应该是/etc/sysconfig/network-scripts/route-enp0s3可以通过以下格式添加：10.0.0.0/24 via 192.168.1.10192.168.100.0/24 via 192.168.1.10192.168.50.10/32 via 192.168.1.1或者通过如下格式添加：ADDRESS0=10.0.0.0NETMASK0=255.255.255.0GATEWAY0=192.168.1.10ADDRESS1=192.168.50.10NETMASK1=255.255.255.255GATEWAY1=192.168.1.1最后通过 nmcli 命令使配置生效：nmcli connection reloadnmcli connection up enp0s3参考链接：https://www.cyberciti.biz/faq/linux-route-add/https://www.cnblogs.com/hf8051/p/4530906.htmlhttps://www.ibm.com/docs/en/aix/7.2?topic=r-route-commandhttps://elearning.wsldp.com/pcmagazine/add-permanent-routes-centos-7/https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-configuring_static_routes_using_nmclihttps://unix.stackexchange.com/questions/501260/where-does-network-manager-store-settingshttps://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-configuring_static_routes_in_ifcfg_files" }, { "title": "envoy proxy调研笔记", "url": "/posts/4a1349e1/", "categories": "Technology, notes", "tags": "IT, k8s, ingress, envoy, proxy", "date": "2022-07-25 20:27:32 +0800", "snippet": "内容提要我们主要想了解 envoy 如何提供 L4/L7的代理服务，envoy具体提供哪些功能，我们如何利用这些功能实现我们的业务场景。在envoy如何提供代理能力方面，主要有两点：1. envoy 如何从控制面获取配置； 2. envoy 如何根据配置信息进行路由。在如何利用envoy提供的功能实现我们的业务场景方面，主要是 如何将 k8s集群中的相关资源对象的描述信息，转换为envoy 的配置。本文我们将围绕以上两个方面，进行介绍，主要有以下相关内容： envoy是什么？为了解决什么问题，具有什么特点，能力边界在哪里。 envoy的基本概念与框架。 明确envoy中的基本术语，以及envoy的基本工作框架，处理流程。 envoy的动态配置能力。控制面如何将k8s集群中的route资源描述信息动态实时地传达到envoy？ envoy如何进行路由？ 有了路由配置信息后，envoy如何对请求进行路由。这部分内容主要聚焦在路由能力，这个能力主要是由http route filter提供。这部分涉及到一些代码实现层面的处理以及相关数据结构。 envoy的主要组件与模型：线程模型、常见组件、过滤器等。 控制面组件实践。 对几个控制面组件的简单对比。 envoy支持特性概览 为了便于评估envoy能够对哪些业务需求提供支持，简单罗列了envoy提供的功能特性。 Envoy 是什么¶根据envoy官网的定义，envoy是一个开源的为云原生应用而设计的边缘和服务代理（edge and service proxy）。使用c++ 编写，设计定位是用于大规模微服务服务网格架构的通用数据平面。为的是解决以下在大规模微服务场景中存在的挑战：1. 复杂异构系统中的网络维护；2. 流量监控中的困难；3. 扩缩容。通常来说有两种部署方式，一种是作为sidecar 和微服务应用部署在一起，将网络相关的逻辑从微服务中抽离出来，提供服务网格的数据面能。另一种部署方式是作为一个代理网关部署，作为微服务集群的流量入口。envoy可以提供的能力有：负载均衡、可用性增强能力（如超时、熔断、重试等）、可观测性、指标监控等。envoy的一大特点是可以通过xDS实现实时的动态配置更新。在k8s容器集群中，部署的应用会不停地新增、减少、漂移，路由配置会不停地发生变化，xDS 这一特性能很好地在这种频繁发生路由配置变化的场景下高效运作。不仅仅是路由相关的配置可以热加载生效，envoy 可以通过xds进行除本身二进制文件之外的几乎所有变更，也就是除非需要更新envoy本身，否则任何变更都无需将envoy停止运行，这为我们的运维变更带来了极大的便利性。除了支持xds进行动态配置，envoy也支持进行静态配置，但是通常来说，由于其配置具有很高的灵活度，也导致了配置具有较高的复杂性，难以人工维护，通常来说都是由代码生成。envoy只扮演数据平面的角色，不扮演控制平面的角色。尽管envoy适用于k8s集群云原生场景，但是并不会对k8s集群的路由相关资源进行监控，并转换为相关的路由配置。因此我们需要有控制面程序来完成对k8s集群中路由相关资源进行监控，来完成路由配置的生成，并通过xds将配置同步到envoy中。当前常见的控制面实现有：istio、contour、emissary-ingress（ambassador）、gloo等。以conotur为例，常见的部署形态如下所示：参考链接： https://www.tetrate.io/blog/get-started-with-envoy-in-5-minutes/ https://www.tetrate.io/what-is-envoy-proxy/#:~:text=Introducing Envoy Proxy,data plane for service mesh.envoy的基本概念和框架¶基本概念：https://www.envoyproxy.io/docs/envoy/v1.21.4/intro/arch_overview/intro/terminology：Host：一个逻辑的网络应用。一个物理设备上可以共存多个hosts，只要他们能够独立寻址。Downstream：downstream host与envoy建立连接，向envoy发送请求，从envoy获得response。Upstream：upstream host接收来自envoy的连接，接受请求，并返回response。Listener：一个 listener 是一个命名的网络位置，downstream hosts可以与这个网络位置建立连接。envoy会暴露一个或多个listener供downstream hosts连接。Cluster：一个 cluster是一组逻辑上相近的upstream hosts，envoy会与之建立连接。envoy 可以通过service discovery 发现cluster 的hosts 成员。一个请求到来，确定会被路由到一个cluster 时，会通过指定的负载均衡策略确定将请求发送到这个cluster 中的哪个host。Mesh ： **envoy mesh是一组envoy proxies组成的，为许多不同的service 和 应用平台提供 消息传输的底层设施。Runtime configuration： 带外实时配置系统与特使一起部署。可以更改配置设置，从而影响操作，而无需重新启动Envoy或更改主要配置。基本术语：https://www.envoyproxy.io/docs/envoy/v1.21.4/intro/life_of_a_request： Cluster: a logical service with a set of endpoints that Envoy forwards requests to. 一个由一组endpoints组成的逻辑的service，envoy将请求发往cluster。 Downstream: an entity connecting to Envoy. This may be a local application (in a sidecar model) or a network node. In non-sidecar models, this is a remote client. Endpoints: network nodes that implement a logical service. They are grouped into clusters. Endpoints in a cluster are upstream of an Envoy proxy. 对应于pod节点、或者一个host节点 Filter: a module in the connection or request processing pipeline providing some aspect of request handling. An analogy from Unix is the composition of small utilities (filters) with Unix pipes (filter chains). Filter chain: a series of filters. listener 后面可以绑定 filter chain，发送到listener上的请求进来之后，就会经过这个filter chain上的filter 的处理。 Listeners: Envoy module responsible for binding to an IP/port, accepting new TCP connections (or UDP datagrams) and orchestrating the downstream facing aspects of request processing. 可以理解为定义的暴露给下游连接的socket server Upstream: an endpoint (network node) that Envoy connects to when forwarding requests for a service. This may be a local application (in a sidecar model) or a network node. In non-sidecar models, this corresponds with a remote backend.提问： filter chain 上在 filter 间传递处理的是什么？基本框架：关键子系统envoy的核心能力是处理流量，当一个请求到来时，主要经历envoy 中两个主要子系统的处理（ref）： Listener subsystem：处理来自downstream的请求，同时负责管理downstream的请求的生命周期，并负责传输response。downstream的http/2编解码器就属于这个组件。 Cluster subsystem：负责选择和管理到upstream endpoint的连接。这个组件管理 上游 cluster 和 endpoint的健康新情况，进行负载均衡，管理连接池。upstream的 http/2 编解码器属于这个组件。我们使用上面的Listener subsystem和Cluster subsystem来指代由顶级 ListenerManager 和 ClusterManager 类创建的模块组和实例类。这两个子系统由 http router filter连接起来，http route filter通常来说是 listener 上的filter chain 的最后一个filter。http router filter 的作用是确定将来自downstream 的request 发送到哪个 upstream。也就是负责十分关键的路由环节，其过程将在后面章节进行描述。线程模型Envoy使用单进程多线程架构，有一个基于事件的线程模型。其中一个扮演主线程的控制各种协调任务，而一些工作线程负责监听、过滤和转发。一旦某个链接被监听器 Listener接受，那么这个链接将会剩余的生命周期绑定在这个 Woker 线程。这种架构会使得大部分工作工作在单线程的情况下，只有少量的工作会涉及到线程间通信，这使得Envoy代码是非阻塞的。（参考）流量生命周期 Listener TCP accept¶worker thread 持有自己的一个Listener 实例，当新的tcp连接到来时，内核决定由哪个worker thread接受请求进行处理。 Listener filter chains and network filter chain matching¶Listener接受请求后，依次调用 Listener filter chain 和 network filter chain对请求进行处理。Envoy 会在network filters之前处理listener fileters。我们可以在listener fileters中操作连接元数据，通常是为了影响后来的filters或集群如何处理连接。listener filters 对新接受的socket进行操作，并可以停止或随后继续执行进一步的filter。listener filter的顺序很重要，因为 Envoy 在listener接受socket后，在创建连接前，会按顺序处理这些filter。我们可以使用listener filters的结果来进行filter匹配，并选择一个合适的network filter chain。例如，我们可以使用 HTTP 检查器监听器过滤器来确定 HTTP 协议（HTTP/1.1 或 HTTP/2）。基于这个结果，我们就可以选择并运行不同的network filter chain。 TLS transport socket decryption¶卸载TLS Network filter chain processing¶接下来就进入 network filter chain的处理阶段，处理http 的listener的 network filter chain 的最后一个filter是 http connection manager（HCM）。HCM 负责创建 http/2 编解码器 以及管理 http filter chain。结合前面的处理流程，一个请求进来之后的处理流程如下图所示： HTTP/2 codec decoding¶进行解码，使后续处理协议无关 HTTP filter chain processing¶HCM 中 filter chain 处理流程大致如下图：HCM 的filter chain中最后一个filter 为 route filter ，负责选定route configuration， 确定upstream cluster。当route filter被调用，路由选择过程就完成了。所选路由的配置将指向上游集群名称。然后，路由器过滤器向 ClusterManager 请求集群的 HTTP 连接池。 Load balancing¶每个cluster都有一个负载均衡器，它在新请求到达时选择一个endpoint。一旦选择了一个endpoint，这个endpoint的连接池就被用来寻找一个连接来转发请求。 HTTP/2 codec encoding¶进行 http/2 编码 TLS transport socket encryption¶进行 tls 传输加密 Response path and HTTP lifecycle¶response 以与request 相反的顺序经历 http filters 和 network filters。在request 处理时调用的是filter 的decoder，对response进行处理时调用的是filter 的encoder，关于这个的详细信息，在后面对filter 进行介绍时会进行更加清楚的描述。 Post-request processing¶请求完成后，流会被销毁，同时还会进行一些后置处理： 统计信息更新（例如timing, active requests, upgrades, health checks） access log 记录 trace span 完成。trace span 描述请求的持续时间和详细信息。envoy动态配置 （xDS）¶概念介绍当使用动态配置时，我们不需要重新启动 Envoy 进程就可以生效。相反，Envoy 通过从磁盘或网络上的文件读取配置，动态地重新加载配置。动态配置使用所谓的发现服务 API，指向配置的特定部分。这些 API 也被统称为 xDS。当使用 xDS 时，Envoy 调用外部基于 gRPC/REST 的配置provider，这些provider实现了发现服务 API 来检索配置。外部基于 gRPC/REST 的配置提供者也被称为控制平面。当使用磁盘上的文件时，我们不需要控制平面。Envoy 提供了控制平面的 Golang 实现，但是 Java 和其他控制平面的实现也可以使用。xDS发现服务Envoy 内部有多个发现服务 API，分别对应一个资源类型。所有这些在下表中都有描述。Untitled聚合发现服务（ADS）表中的发现服务是独立的，有不同的 gRPC/REST 服务名称。使用聚合发现服务（ADS），我们可以使用一个单一的 gRPC 服务，在一个 gRPC 流中支持所有的资源类型（监听器、路由、集群…）。ADS 还能确保不同资源的更新顺序正确。请注意，ADS 只支持 gRPC。如果没有 ADS，我们就需要协调其他 gRPC 流来实现正确的更新顺序。In general, to avoid traffic drop, sequencing of updates should follow a make before break model, wherein: CDS updates (if any) must always be pushed first. EDS updates (if any) must arrive after CDS updates for the respective clusters. LDS updates must arrive after corresponding CDS/EDS updates. RDS updates related to the newly added listeners must arrive after CDS/EDS/LDS updates. VHDS updates (if any) related to the newly added RouteConfigurations must arrive after RDS updates. Stale CDS clusters and related EDS endpoints (ones no longer being referenced) can then be removed.增量 gRPC xDS全量模式下，每次我们订阅或每次我们发送资源更新时，我们必须包括所有的资源。例如，每次 RDS 更新必须包含每条路由。如果我们不包括一个路由，Envoy 会认为该路由已被删除。这样做更新会导致很高的带宽和计算成本，特别是当有大量的资源在网络上被发送时。Envoy 支持 xDS 的 delta 变体，我们可以只包括我们想添加 / 删除 / 更新的资源，以改善这种情况。关于envoy xDS 动态配置接口的更多信息见链接。总结关于xDS小结如下：数据来源三种xds配置数据来源：文件系统、rest接口、grpc stream 文件系统：envoy 监控指定的文件，当文件内容发生变化时，加载生效。 rest接口：控制平面 xDS server 提供的是rest 接口供 envoy 调用获取配置信息，这种模式下，需要envoy 主动进行polling，需要考虑polling周期和性能消耗。 grpc stream：控制平面 xDS server 提供 grpc stream服务，envoy 与server建立连接，订阅资源，控制面通过流实时将配置同步到envoy。四种变体两个纬度： State of the World (SotW) vs. incremental. 全量更新 vs 增量更新 xDS vs ADS 每个资源类型一个gRPC 流 vs 集成所有资源类型在一个gRPC 流 两个纬度的不同变体组合出四种变体： State of the World (Basic xDS): SotW, separate gRPC stream for each resource type Incremental xDS: incremental, separate gRPC stream for each resource type Aggregated Discovery Service (ADS): SotW, aggregate stream for all resource types Incremental ADS: incremental, aggregate stream for all resource typescontour只提供了 SotW的stream模式，这意味着cluster 和 Listener 这两个资源的订阅和更新需要是全量的。而其他资源可以依托于其他关联资源，以一定的粒度进行全量更新。（The SotW approach was the original mechanism used by xDS, in which the client must specify all resource names it is interested in with each request, and for LDS and CDS resources, the server must return all resources that the client has subscribed to in each request.）摘自此处。以订阅流程为例：DiscoveryRequest 中的 resource_names 信息作为资源订阅标识出现。 Cluster 和 Listener 将使用一个空的 resource_names，因为 Envoy 需要获取管理服务器对应于节点标识的所有 Cluster（CDS）和 Listener（LDS）。对于其他资源类型，如 RouteConfigurations（RDS）和 ClusterLoadAssignments（EDS），则遵循此前的 CDS/LDS 更新，Envoy 能够明确地枚举这些资源。envoy如何进行路由¶envoy.filters.http.router的主要工作是查看路由表，并对请求进行相应的路由，包括转发和重定向。http filter 使用传入的请求信息，根据虚拟主机信息和路由规则将请求与上游集群相匹配，匹配的上游集群可能有多个，这时会从上游集群中选择出一个，然后在该集群内根据配置的负载均衡策略选择个上游endpoint进行请求转发。主要流程当一个 HTTP 请求进来时，虚拟主机、域名和路由匹配依次发生。 host或authority头被匹配到每个虚拟主机的domains字段中指定的值。例如，如果主机头被设置为 foo.io，则虚拟主机 foo_vhost 匹配。 接下来会检查匹配的虚拟主机内routs下的条目。如果发现匹配，就不做进一步检查，而是选择一个集群。例如，如果我们匹配了 foo.io 虚拟主机，并且请求前缀是 /api，那么集群 foo_io_api 就被选中。 如果提供，虚拟主机中的每个虚拟集群（virtual_clusters）都会被检查是否匹配。如果有匹配的，就使用一个虚拟集群，而不再进行进一步的虚拟集群检查。因此，虚拟主机的顺序以及每个主机内的路由都很重要。数据结构从代码实现层面来看，匹配流程及使用到的数据结构大致如下：一个请求过来之后，会通过 请求中的host信息去找到对应的 virtual_host 的配置信息，然后在从 virtual_host 的配置信息中选取出 匹配 的 route 项，route项里面明确了要发送的 cluster ， 也就是我们集群里面的应用service主要就是： 从config中findVirtualHost 从VirtualHost中getRouteFromEntriesconfig中结构大致如下：主要有三个map： virtual_hosts_、wildcard_virtual_host_suffixes_、wildcard_virtual_host_prefixes_{virtual_hosts_ VirtualHostswildcard_virtual_host_suffixes_ WildcardVirtualHostswildcard_virtual_host_prefixes_ WildcardVirtualHosts}VirtualHosts 是一个map， 结构为：map&amp;lt;host, VirtualHost&amp;gt;WildcardVirtualHosts 是一个嵌套map， 结构为： map&amp;lt;length_of_host，map&amp;lt;host, VirtualHost»VirtualHost 中存有 routeEntry， 存在 vector中，routeEntry 有 各种 匹配规则结合上面所述的存储结构，路由匹配的过程执行的步骤大致如下： 从config中findVirtualHost 依次从 virtual_hosts_、wildcard_virtual_host_suffixes_、wildcard_virtual_host_prefixes_ 查找 VirtualHost virtual_hosts_ 中是直接 通过key查找； wildcard_virtual_host_suffixes_、wildcard_virtual_host_prefixes_ 是 根据最长匹配的优先原则，按 length_of_host 由大到小，在map&amp;lt;host, VirtualHost&amp;gt; 中 通过 key 查找。如果所有map中都没有匹配的对象，则返回default_virtual_host. 从VirtualHost中getRouteFromEntries这个步骤是遍历 vector 进行匹配，发现匹配的 routeEntry就返回，不再管后面有没有匹配的routeEntry 完整域名匹配的情况容易理解，以下补充说明在前缀匹配和后缀匹配情形下的匹配流程，wildcard_virtual_host_suffixes_ 的结构大致如下：{ 6: { &quot;.a.com&quot;: VirtualHost, &quot;.b.com&quot;: VirtualHost }, 5: { &quot;.a.cn&quot;: VirtualHost, &quot;.c.cn&quot;: VirtualHost }}匹配的时候会根据长度遍历一级map，对二级map根据域名的子字符串hash查找符合的virtual host。这种方式可以较好地降低匹配的成本。前缀匹配的逻辑与之大致相同。请求匹配条件根据前面的内容，对根据域名选取出对应的virtual host 的过程已经比较明确，接下来对如何从virtual host中匹配出符合条件的routeEntry 进行介绍。从virtual host 中匹配出符合条件的routeEntry 并没有什么特别的处理手法，就是进行顺序匹配，值得注意的是，一旦有符合匹配条件的routeEntry出现，就不会再继续进行匹配，因此在配置路由规则时，顺序是十分重要的。那么routeEntry中可以配置些什么匹配条件呢？ 路径匹配 prefix：前缀匹配 path：全路径匹配 safe_rege：根据正则表达式匹配 connect_matcher: 只匹配connect请求（alpha） header匹配可指定一组 Header，根据路由配置中所有指定的 Header 检查请求 Header。如果所有指定的头信息都存在于请求中，并且设置了相同的值，则进行匹配。多个匹配规则可以应用于Header： range_match：范围匹配，检查请求header 中的值是否在指定的十进制整数范围内。支持负数。 present_match: 存在匹配，key是否存在 string_match: 字符串匹配 regex_match exact_match prefix_match suffix_match contains_match 示例：- match: prefix: &quot;/&quot; headers: # 头部`regex_match`匹配所提供的正则表达式 - name: regex_match string_match: safe_regex_match: google_re2: {} regex: &quot;^v\\\\d+$&quot; # Header `exact_match`包含值`hello`。 - name: exact_match string_match: exact:&quot;hello&quot; # 头部`prefix_match`以`api`开头。 - name: prefix_match string_match: prefix:&quot;api&quot; # 头部`后缀_match`以`_1`结束 - name: suffix_match string_match: suffix: &quot;_1&quot; # 头部`contains_match`包含值 &quot;debug&quot; - name: contains_match string_match: contains: &quot;debug&quot; invert_match 反转匹配，invert_match 可以被其他匹配器使用。例如： - match: prefix: &quot;/&quot; headers: - name: env contains_match: &quot;test&quot; invert_match: true上面的片段将检查 env 头的值是否包含字符串test。如果我们设置了 env 头，并且它不包括字符串test，那么整个匹配的评估结果为真。需要注意的是，invert_match 不是直接对匹配结果取反，以上面的例子为例，invert_match 为false时，匹配条件表示 env 存在，且值包含 test；invert_match 为true的时候，不是前面条件的取反，也就是不是 “env 不存在 或 env 存在且值不包含test” ，而是仅仅表示 “env 存在，且其值不包含test”。 query_parameters 查询参数匹配 使用 query_parameters字段，我们可以指定路由应该匹配的 URL 查询的参数。过滤器将检查来自path头的查询字符串，并将其与所提供的参数进行比较。 ​ query_parameters匹配规则: 规则名称 描述 exact 必须与查询参数的精确值相匹配 prefix 前缀必须符合查询参数值的开头 suffix 后缀必须符合查询参数值的结尾 safe_regex 查询参数值必须符合指定的正则表达式 contains 检查查询参数值是否包含一个特定的字符串 除了上述规则外，我们还可以使用 ignore_case字段来指示精确、前缀或后缀匹配是否应该区分大小写。如果设置为 “true”，匹配就不区分大小写。例子1:- match: prefix: &quot;/&quot; query_parameters: - name: env present_match: true如果有一个名为 env 的查询参数被设置，上面的片段将评估为真。它没有说任何关于该值的事情。它只是检查它是否存在。例如，使用上述匹配器，下面的请求将被评估为真。GET /hello?env=test例子2: 使用前缀规则进行不区分大小写的查询参数匹配- match: prefix: &quot;/&quot; query_parameters: - name: env string_match: prefix: &quot;env_&quot; ignore_case: true如果有一个名为 env的查询参数，其值以 env_开头，则上述内容将评估为真。例如env_staging和 ENV_prod评估为真。 gRPC 和 TLS 匹配器 gRPC 匹配器将只在 gRPC 请求上匹配。 TLS 匹配器，它将根据提供的选项来匹配 TLS 上下文。 利用envoy提供的以上请求匹配能力，我们可以灵活组合出符合业务场景的匹配条件，使得不同的请求可以按照我们的意图发送到不同的upstream clusters。upstream cluster 与 endpoint选择当一个请求过来，经过前面的域名以及其他条件的匹配后，会选择出一个routeEntry，接下来将会从routeEntry中选择出一个upstream cluster 进行请求转发。一个routeEntry可以关联一个或多个upstream cluster，当关联一个cluster时，则使用该cluster。当routeEntry中关联多个upstream cluster，通常是关联多个weight cluster 的场景，此时会根据权重随机选择一个cluster。随机选择cluster 的流程是 根据请求，产生一个数，将该数按总权重取模，并根据取模后的值所在的区间确定选择哪个cluster。在1.21.x 版本的envoy上，在weight cluster 中有 header name 属性，通过指定这个值，可以由用户通过指定的header 传入“随机值”，如果用户指定来该属性值，且在请求中携带了合法有效的数值，则将使用该值，否则生成一个随机值。mark todo：由于在验证流量分割比例的时候，发现存在比例偏离较大的情况，对这个随机值的生成方式存在一些疑惑点，待查明。在确定upstream cluster后，会根据指定的负载均衡策略从cluster 的 endpoint中选择一个endpoint进行流量转发。envoy支持的负载均衡策略有（ref）： Weighted round robin Weighted least request Ring hash Maglev Random一旦选择了一个endpoint，这个endpoint的连接池就被用来寻找一个连接来转发请求。如果不存在与主机的连接，或者所有连接都处于最大并发流限制，则会建立一个新连接并将其放置在连接池中，除非集群的最大连接断路器已经触发熔断。如果配置了并达到了连接的最大生命周期流限制，则会在池中分配一个新连接，并丢弃受影响的 HTTP/2 连接。envoy的重要组件与模型¶envoy线程模型Envoy 有一个基于事件的线程模型。一个主线程负责服务器生命周期、配置处理、统计等以及一些工作线程处理请求。所有线程都围绕一个事件循环 (libevent) 运行，并且任何给定的下游 TCP 连接（包括其上的所有多路复用流）将在其生命周期内仅由一个工作线程处理。每个工作线程都维护自己的与上游端点的 TCP 连接池。 UDP 处理利用 SO_REUSEPORT 让内核始终将源/目标 IP:port 元组散列到同一个工作线程。 UDP 过滤器状态为给定的工作线程共享，过滤器负责根据需要提供会话语义。这与我们在下面讨论的面向连接的 TCP 过滤器形成对比，其中过滤器状态存在于每个连接上，并且在 HTTP 过滤器的情况下，是基于每个请求的。工作线程很少共享状态并以微不足道的并行方式运行。这种线程模型可以扩展到非常高核心数的 CPU。线程间极少需要共享数据，使得线程的运行可以避免阻塞。Listener和worker threadListenerManager 负责获取表示Listener的配置并实例化绑定到各自 IP/端口的多个Listener实例。Listener可能处于以下三种状态之一： Warming：Listener正在等待配置依赖（例如路由配置、动态秘密）。Listener尚未准备好接受 TCP 连接。 Active：Listener绑定到其 IP/端口并接受 TCP 连接。 Draining：Listener不再接受新的 TCP 连接，而其现有的 TCP 连接被允许继续运行一段时间。每个worker thread为每个配置的Listener维护自己的Listener实例。每个Listener可以通过 SO_REUSEPORT 绑定到同一个端口，或者共享一个绑定到这个端口的socket。当一个新的 TCP 连接到达时，内核决定哪个worker thread将接受该连接，并且该worker thread的Listener将调用其 Server::ConnectionHandlerImpl::ActiveTcpListener::onAccept() 回调。连接池集群中的每个端点将有一个或多个连接池。例如，根据所支持的上游协议，每个协议可能有一个连接池分配。Envoy 中的每个工作线程也为每个集群维护其连接池。例如，如果 Envoy 有两个线程和一个同时支持 HTTP/1 和 HTTP/2 的集群，将至少有四个连接池。连接池的方式是基于底层线程协议的。对于 HTTP/1.1，连接池根据需要获取端点的连接（最多到断路限制）。当请求变得可用时，它们就被绑定到连接上。 当使用 HTTP/2 时，连接池在一个连接上复用多个请求，最多到  max_concurrent_streams 和 max_requests_per_connections 指定的限制。HTTP/2 连接池建立尽可能多的连接，以满足请求。envoy过滤器 http过滤器envoy支持一系列的http filter，这些filter对http级别的消息进行处理，不知道底层协议或复用。有三种类型的http过滤器： decoder： 在请求路径上调用 encoder：在响应路径上调用 decoder/encoder： 在请求和响应路径上都会被调用假设有如下filter chain： 在请求路径上的调用情况如下： 在响应路径上的调用情况如下：单个http filter可以停止或继续执行后续的filter，并在单个请求流的范围内相互分享状态。通常来说，filter chain上的最后一个filter 是 route filter 。内置http filter：CORS、CORS、健康检查、JWT认证等http filter列表：https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_filters/http_filters#config-http-filters控制面选型¶当前基于 envoy 提供的控制面主要有 istio、emissary-ingress（ambassador）、contour、gloo等，其中istio主要是实现 service mesh，我们想要envoy 作为 api gateway 存在，主要考察 emissary-ingress（ambassador）、contour、gloo。由于都是基于envoy 的控制面，所以他们能够提供的特性，取决于envoy本身的特性，在基本能力的支持上没有大的差异。项目github相关指标 project watch fork star issue(open/closed) bug issue gloo 108 348 3.4k 945/1991 310/670 contour 80 561 3.1k 390/1317 50/253 emissary-ingress 87 612 3.8k 315/1123 12/62 可见gloo的bug issue 数量较大。gateway api支持情况 emissary now supports a limited subset of the new v1alpha1Gateway API contour now exclusively supports Gateway API v1alpha2, the latest available version. 支持envoy版本情况：调研时发现，emissary-ingress使用的envoy版本为 1.17.4，但envoy在调研时已经迭代到1.22.x 的发布版本。 emissary ingress envoy 2.1.0 7a33e53fd3d3c4befa53030797f344fcacaa61f4/1.17.4-dev/Modified/RELEASE/BoringSSL 2.2.0 049f125c1c9a6cd7e49bd4a660cdeccd9f6ec383/1.17.4/Modified/RELEASE/BoringSSL contour在调研时支持的是1.21.x版本。envoy每个版本会增加一些新的功能，可能会带来api 的变化，导致版本之间可能是不兼容的。比如contour 1.20.1 支持envoy 1.21.x ，无法和envoy 1.22.x 有效对接。考虑到bug issue 和 版本支持的情况，目前选择了contour 进行开发适配。envoy支持特性概览¶ 自动健康探测 被动健康探测 自动重试 熔断 局部速率限制 全局速率限制（需使用外部速率限制服务） 影子请求（流量镜像） 异常点检测（被动健康探测） 请求对冲 tls卸载 http/1.1 http/2 http/3 （alpha） websockets L3/L4 路由 L7 路由 一流的观察性：日志、指标、tracing(请求id生成和追踪) 流量分割 操作header信息（包括request的header以及 response的header） timeout配置相关内容： envoy 动态路由配置信息查看 envoy proxy调研笔记" }, { "title": "使用make进行golang编译中的小问题及解决方案", "url": "/posts/61a056t8/", "categories": "Technology, notes", "tags": "IT, golang, make", "date": "2022-07-02 03:29:38 +0800", "snippet": " 报错信息：Clock skew detected. Your build may be incomplete.make: Warning: Clock skew detected. Your build may be incomplete.表示检测到了时钟偏差，通常发生在将代码从开发主机拷贝到编译主机进行编译，而两个设备系统之间的时间上存在差距。解决方案：find ./ -type f | xargs touch将所有文件进行一次touch，刷新时间为本地时间，然后进行编译 报错信息：no required module provides package main.go; to add it: go get main.go 解决方案修改 makefile中 build 的命令行：由 go build -o bin/manager main.go改为： go build -o bin/manager ${MODULE}/path/to/the/dir/of/main.go${MODULE} 为当前项目module值，可在 go.mod中获取，即开头的 module值/path/to/the/dir/of/main.go 为main.go所在目录在本项目中的相对路径" }, { "title": "envoy 动态路由配置信息查看", "url": "/posts/61a05b5d/", "categories": "Technology, notes", "tags": "IT, envoy, contour, ingress, k8s", "date": "2022-05-09 22:13:26 +0800", "snippet": "envoy 通过静态配置和动态配置接口共同决定 路由配置信息。在contour + envoy 的部署使用模式下，envoy 的静态配置中主要定义了如何从contour 获取动态配置信息，而contour 作为 envoy 的控制面 xds server运行，将从k8s 集群 的ingress 资源描述中获取到的路由信息通过xds发送给 envoy。因此，我们可以通过两种方式来获取 envoy路由配置的相关信息： 一种是通过contour 暴露的接口，去看 contour 给 envoy 发送的内容 一种是通过 envoy 暴露的接口去看envoy接收生效的内容查看 contour发送的内容contour 提供了命令行交互能力，可以执行命令 contour cli eds 等命令去获取endpoint等配置的信息。相关命令：获取 contour pod信息：CONTOUR_POD=$(kubectl -n projectcontour get pod -l app=contour -o jsonpath=&#39;{.items[0].metadata.name}&#39;)进入该pod执行查看命令：kubectl -n projectcontour exec ${CONTOUR_POD} -c contour -- contour cli eds --cafile=/certs/ca.crt --cert-file=/certs/tls.crt --key-file=/certs/tls.key其中eds 表示查看 endpoint 相关配置支持以下基本信息查看： eds： endpoint 信息 cds： cluster信息 rds： route信息 lds： listener 信息注意这个是一个持续监听的接口，执行后不会退出，当k8s集群ingress相关资源对象发生变化时，又或获取最新配置内容。查看envoy收到生效的配置内容contour 提供 shutdown-manager 的 envoy pod中，会通过 9001 端口暴露一个进行了过滤的管理接口，提供了以下一些路由相关配置的获取接口： /clusters /listeners /config_dump (全量配置)因为pod上没有做9001端口的暴露，我们通过kubectl port-forward 去作转发：kubectl -n projectcontour port-forward --address 0.0.0.0 ${pod-name} ${local-port}:9001例如：在ip为xx.xx.xx.xx的节点上对 pod/envoy-xxxxx 进行端口转发，指定本地转发端口为9901：kubectl -n projectcontour port-forward --address 0.0.0.0 pod/envoy-xxxxx 9901:9001访问以下地址可获取配置信息：http://xx.xx.xx.xx:9901/config_dump如果想将配置信息dump到文件，可将返回内容重定向到文件curl http://xx.xx.xx.xx:9901/config_dump &amp;gt; ./envoy_config.dump" }, { "title": "wait非子进程退出", "url": "/posts/2c936b7c/", "categories": "Technology, notes", "tags": "IT, linux, process, waitpid, pidfd_open, configProcEvents", "date": "2022-03-12 22:35:18 +0800", "snippet": "背景有这样一个业务场景，需要主进程可以监测它创建的子进程是否还存活，通常来说使用 waitpid 来获取子进程的状态变化情况，就可以实现需求。但是我们希望在主进程异常退出重启后还能够监测之前创建的子进程的存活情况，但是waitpid 又只能针对子进程使用。于是就有了以下问题： 为什么waitpid只能针对子进程使用？ 有没有什么方法可以改变子进程的父进程？ 有没有什么方式可以监测非子进程的退出，或者是其他状态变化？为什么waitpid只能针对子进程使用？wait, waitpid, waitid 这三个系统函数都是为了等待进程状态发生变化。#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/wait.h&amp;gt;pid_t wait(int *status);pid_t waitpid(pid_t pid, int *status, int options);int waitid(idtype_t idtype, id_t id, siginfo_t *infop, int options);这三个系统调用都是用于等待调用进程的子进程的状态改变，并获取到子进程状态变化的相关信息。状态变化包括：子进程终止、子进程收到信号停止、子进程收到信号被唤醒。当进程退出的时候，会进程资源会被回收，但是包含进程pid、进程退出状态、资源使用信息等的一个“最小信息集”会被保留，会在进程表中占用一个位置。当父进程使用 wait 系列函数时可以获取到已经终止的子进程的最小信息集所含信息，同时这些信息被清理，占用的进程表资源被回收。如果父进程没有wait并回收掉已经终结的子进程的进程表资源，子进程就会成为僵尸进程（zombies）。如果进程资源始终占用着进程表资源，将进程表资源耗尽，使得系统无法再创建新的进程。如果父进程终止了，那么僵尸进程会被系统一号进程领养，并由一号进程自动执行 wait 调用，将僵尸进程清理、将所占用的资源回收。关于这个几个函数的使用细节可以查看 man 手册，有以下几点值得注意： 如果父进程在调用 wait 函数时，子进程的状态已经发生了变化，那么调用会立即返回，否则，会阻塞。但是这个行为可以通过options参数进行配置， options 是一个位控制参数， options 配置上 WNOHANG 时可以是调用不阻塞，而是立即返回。 默认情况下 wait 函数只等待 子进程退出进入终结态的情况，这个行为可以通过options参数进行配置，配置上 WUNTRACED 时可以 wait 子进程进入 stop 状态，配置上 WCONTINUED 可以 wait 处于 stop 状态中的进程被 SIGCONT 信号唤醒。 status 参数不为 NULL 时，可以接受进程状态变化的相关信息，这些信息可以通过 相关宏对 status 处理得到。 当 对非子进程调用 wait 系列函数时，会返回错误 ECHILD。当 对非子进程调用 wait 系列函数时，会返回错误 ECHILD。那么为什么呢？根据这个回答，这是由于 wait 函数的工作机制，在 POSIX 系统中，子进程退出时，系统会对其父进程发送 SIGCHLD 信号（参考），而在子进程还没有退出的情况调用 wait 函数，就会一直阻塞等待这个信号到来。因为系统只会对终结掉的进程的父进程发送该信号，因此 wait 系列函数只能对子进程调用。不过这只能解释 wait 进程终结的应用场景进行解释，对 wait 子进程的其他状态变化，如进入 stop 状态和 从 stop 状态重新被唤醒，并不能合理解释。不过机理应该大致类似，这个后续有待研究。ref： https://linux.die.net/man/2/waitpid https://www.ibm.com/docs/en/zos/2.4.0?topic=functions-waitpid-wait-specific-child-process-end https://linuxhint.com/waitpid-syscall-in-c/ https://unix.stackexchange.com/questions/214908/why-can-the-waitpid-system-call-only-be-used-with-child-processes能否改变子进程的父进程？既然 wait 系列函数只能用于非子进程，那么如果可以改变 进程的父进程，也就可以对原本不是 子进程的进程使用 wait 系列函数。那有没有什么方法可以改变子进程的父进程？根据这个回答，在系统内核外是不能对 进程的父进程信息进行配置修改的，而系统并没有提供相关的系统调用来完成这样的操作。内核只会在进程的父进程退出后，将子进程的 ppid 改为 1 号进程。能否监测非子进程的退出或状态变化？有没有什么方式可以监测非子进程的退出，或者是其他状态变化？找到三种方式：1.利用 kill 探测进程的存活情况调用 kill(pid, 0)， 如果返回值是 -1， 而且 errno 是 ESRCH ，就表示进程已经结束退出。这个方法也可以用在命令行中：while kill -0 $PID 2&amp;gt;/dev/null; do sleep 1; done或者也可以使用探测 /proc/$pid 是否存在的方式来探知。同样在命令行中利用 ps 等命令检索也可以达到目的。2.使用 pidfd_open 来在任意进程结束时获得通知从 linux kernel 5.3 开始系统调用 pidfd_open 可以对给定的 pid 创建一个文件描述符。 这个文件描述符可以用于执行poll操作，在进程退出时获得notification。参考man手册,使用方法如下：The program below opens a PID file descriptor for the process whose PID is specified as its command-line argument. It then uses poll(2) to monitor the file descriptor for process exit, as indicated by an EPOLLIN event. Program source #define _GNU_SOURCE #include &amp;lt;sys/types.h&amp;gt; #include &amp;lt;sys/syscall.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; #include &amp;lt;poll.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;stdio.h&amp;gt; #ifndef __NR_pidfd_open #define __NR_pidfd_open 434 /* System call # on most architectures */ #endif static int pidfd_open(pid_t pid, unsigned int flags) { return syscall(__NR_pidfd_open, pid, flags); } int main(int argc, char *argv[]) { struct pollfd pollfd; int pidfd, ready; if (argc != 2) { fprintf(stderr, &quot;Usage: %s &amp;lt;pid&amp;gt;\\n&quot;, argv[0]); exit(EXIT_SUCCESS); } pidfd = pidfd_open(atoi(argv[1]), 0); if (pidfd == -1) { perror(&quot;pidfd_open&quot;); exit(EXIT_FAILURE); } pollfd.fd = pidfd; pollfd.events = POLLIN; ready = poll(&amp;amp;pollfd, 1, -1); if (ready == -1) { perror(&quot;poll&quot;); exit(EXIT_FAILURE); } printf(&quot;Events (%#x): POLLIN is %sset\\n&quot;, pollfd.revents, (pollfd.revents &amp;amp; POLLIN) ? &quot;&quot; : &quot;not &quot;); close(pidfd); exit(EXIT_SUCCESS); }3.使用 ptrace attach 到想要 wait 的进程上。但是这个会对被 attach 的进程造成一定的影响，像性能影响什么的。4.配置CONFIG_PROC_EVENTS，使用Report process events to userspace的特性在进程结束时获得通知。这种方式在 github 有相关的项目实现，可以参考.以及相关描述：Report process events to userspacemodulename: cn_proc.koconfigname: CONFIG_PROC_EVENTSLinux Kernel Configuration└─&amp;gt; Device Drivers └─&amp;gt; Connector - unified userspace &amp;lt;-&amp;gt; kernelspace linker └─&amp;gt; Report process events to userspaceProvide a connector that reports process events to userspace. Sendevents such as fork, exec, id change (uid, gid, suid, etc), and exit.ref: https://stackoverflow.com/q/1157700/6364089 https://stackoverflow.com/q/60183544/6364089 https://github.com/stormc/waitforpid/blob/master/waitforpid.c https://www.kernelconfig.io/config_proc_events后记：后续可以对wait系列函数以及系统信号机制做更多调研，弄明白遗留的问题。可以对几种 wait 非子进程的方式做更多的实践。" }, { "title": "学海拾贝-20220227-20220228", "url": "/posts/f5723b2d/", "categories": "Technology, notes", "tags": "notes, IT", "date": "2022-02-28 22:49:22 +0800", "snippet": "问题目录 git merge 时不对message进行确认 Windows上用户名不区分大小写 蓝绿部署、红黑部署、灰度发布 docker no space left on device LVM进行逻辑卷扩容1. git merge 时不对message进行确认在进行 git merge 时会默认进入一个编辑 merge message 的编辑交互中，但是我们有时不希望进行内容变更或不希望进行交互编辑。如果是不进行内容变更，可以使用 --no-edit :git merge test-branch --no-edit如果是不希望进行交互编辑，可以使用 -m 在 merge 时指定 message 内容：git merge test-branch -m &quot;the message that you want to commit&quot;ref: https://git-scm.com/docs/git-merge2. Windows上用户名不区分大小写Windows 下的用户名不区分大小写；但是，密码区分大小写。linux 下的用户名区分大小写。3. 蓝绿部署、红黑部署、灰度发布 蓝绿部署 在蓝绿色部署中，维护两套服务：“蓝色”服务和“绿色”服务。在任意时刻，只有一套服务被用于处理请求。另一套服务处于闲置状态。 进行新版本发布时，我们可以先将闲置状态的服务进行升级，再将生产流量从另一套服务切换过来。蓝绿没有什么特殊含义，只是为了便于区别和表述，我们可以将工作中的服务环境称为蓝色环境，而将闲置环境称为绿色环境。将绿环境部署新版本服务后，进行流量切换。一旦生产流量从蓝色完全转移到绿色，蓝色就可以在回滚或退出生产的情况下保持待机，也可以更新成为下次更新的模板。 ref： https://en.wikipedia.org/wiki/Blue-green_deployment https://docs.cloudfoundry.org/devguide/deploy-apps/blue-green.html https://www.redhat.com/en/topics/devops/what-is-blue-green-deployment 红黑部署 与蓝绿部署类似，红黑发布也是通过两个集群完成软件版本的升级。 当前提供服务的所有机器都运行在红色集群 A 中，当需要发布新版本的时候，具体流程是这样的： 先在云上申请一个黑色集群 B，在 B 上部署新版本的服务； 等到 B 升级完成后，我们一次性地把负载均衡全部指向 B； 把 A 集群从负载均衡列表中删除，并释放集群 A 中所有机器。 这样就完成了一个版本的升级。 同样红黑也只是为了便于表述。 ref： https://stackoverflow.com/questions/45259589/whats-the-difference-between-red-black-deployment-and-blue-green-deployment https://octopus.com/blog/blue-green-red-black 灰度发布 灰度发布，也被叫作金丝雀发布。与蓝绿部署、红黑部署不同的是，灰度发布属于增量发布方法。也就是说，服务升级的过程中，新旧版本会同时为用户提供服务。 灰度发布的具体流程是这样的：在集群的一小部分机器上部署新版本，给一部分用户使用， 以测试新版本的功能和性能；确认没有问题之后，再对整个集群进行升级。简单地说，灰度发布就是把部署好的服务分批次、逐步暴露给越来越多的用户，直到最终完全上线。 ref： https://harness.io/blog/blue-green-canary-deployment-strategies/ https://martinfowler.com/bliki/CanaryRelease.html 4. docker no left space on device问题描述：docker导入镜像时，报错：docker no left space on device但是docker 存储镜像等内容的分区没有更多的空间可以清理出来供其使用了。解决方案：docker system prune执行后会收到提示：WARNING! This will remove: - all stopped containers - all networks not used by at least one container - all dangling images - all dangling build cacheAre you sure you want to continue? [y/N]如果继续执行，将会进行永久性的清理。根据 [docker 提供的最佳实践建议]（https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#create-ephemeral-containers），容器的定位应该是短暂生命周期的，意味着可以随时停止并删除。因此清理掉停止的容器应是安全的。ref：https://jhooq.com/docker-error-no-space-left/https://stackoverflow.com/questions/30604846/docker-error-no-space-left-on-device5. LVM 进行逻辑卷扩容术语： 物理存储介质（The physical media）：这里指系统的存储设备：硬盘，如：/dev/hda1、/dev/sda等等，是存储系统最低层的存储单元。 物理卷（physical volume）PV：物理卷就是指硬盘分区或从逻辑上与磁盘分区具有同样功能的设备(如RAID)，是LVM的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，却包含有与LVM相关的管理参数。 卷组（Volume Group）VG：LVM卷组类似于非LVM系统中的物理硬盘，其由物理卷组成。可以在卷组上创建一个或多个“LVM分区”（逻辑卷），LVM卷组由一个或多个物理卷组成。 逻辑卷（logical volume）LV：LVM的逻辑卷类似于非LVM系统中的硬盘分区，在逻辑卷之上可以建立文件系统(比如/home或者/usr等)。 物理块（physical extent）PE：每一个物理卷被划分为称为PE(Physical Extents)的基本单元，具有唯一编号的PE是可以被LVM寻址的最小单元。PE的大小是可配置的，默认为4MB。 逻辑块（logical extent）LE：逻辑卷也被划分为被称为LE(Logical Extents) 的可被寻址的基本单位。在同一个卷组中，LE的大小和PE是相同的，并且一一对应。LVM的管理命令： 功能 物理卷管理（pv） 卷组管理（vg） 逻辑卷管理（lv） 扫描（scan） pvscan vgscan lvscan 创建（create） pvcreate vgcreate lvcreate 显示（display） pvdisplay vgdisplay lvdisplay 删除（remove） pvremove vgremove lvremove 扩展（extend） — vgextend lvextend 缩减（reduce） — vgreduce lvreduce 逻辑卷扩容步骤 vgdisplay 查看卷组情况--- Volume group --- VG Name volume-group1 System ID Format lvm2 Metadata Areas 3 Metadata Sequence No 1 VG Access read/write VG Status resizable MAX LV 0 Cur LV 0 Open LV 0 Max PV 0 Cur PV 3 Act PV 3 VG Size 168.00 GiB PE Size 4.00 MiB Total PE 774 Alloc PE / Size 21248 / 83.00 GiB Free PE / Size 21760 / 85.00 GiB VG UUID bwd2pS-fkAz-lGVZ-qc7C-TaKv-fFUC-IzGNBK可以看到 Free 空间大小 在Free空间范围内进行扩容分配，使用命令 lvextend -L +${extend_size} ${target_lv} ,其中${extend_size} 为待扩容的大小，为数值加上单位，比如 10G , ${target_lv} 为待扩容的逻辑卷 调整分区： 查看文件系统类型 mount |grep ${target_lv} 或者 cat /etc/fstab | grep ${target_lv} 如果 type 不为 xfs, 则使用 resize2fs 进行调整即可: resize2fs ${target_lv} 如果对 xfs 类型的 fs 执行 resize2fs ，会出现如下报错： resize2fs: Bad magic number in super-block while trying to open xxxxxxxxxx Couldn&#39;t find valid filesystem superblock. 如果 type 为 xfs , 则使用 xfs_growfs 命令：xfs_growfs ${target_lv} df -h 查看挂载点，看看大小是否已经成功改变。ref:关于LVM： https://www.cnblogs.com/shoufeng/p/10615452.html https://www.yisu.com/zixun/3865.html https://opensource.com/business/16/9/linux-users-guide-lvm https://linux.cn/article-3218-1.html关于resize2fs error处理： https://stackoverflow.com/questions/26305376/resize2fs-bad-magic-number-in-super-block-while-trying-to-open https://cloud.tencent.com/developer/article/1491805 https://blog.90.vc/archives/164 https://www.cnblogs.com/-abm/p/11349240.html" }, { "title": "学海拾贝-20220221-20220227", "url": "/posts/b45982ff/", "categories": "Technology, notes", "tags": "notes, IT", "date": "2022-02-27 23:01:11 +0800", "snippet": "内容目录 docker run 覆盖原有entrypoint docker 拉取指定架构的镜像 vim块模式进行批量操作 nginx proxy_pass docker latest标签 mac chrome强制刷新 命令行修改密钥密码1. docker run 覆盖原有entrypoint使用 --entrypointdocker run --entrypoint &amp;lt;new command&amp;gt; [docker_image]以命令行交互模式运行容器进行交互操作：docker run -it --entrypoint /bin/bash [docker_image]更多信息，比如对于 entrypoint 和 cmd 的区别等，可参考： https://docs.docker.com/engine/reference/run/#entrypoint-default-command-to-execute-at-runtime https://phoenixnap.com/kb/docker-run-override-entrypoint https://yeasy.gitbook.io/docker_practice/image/dockerfile/entrypoint https://www.bmc.com/blogs/docker-cmd-vs-entrypoint/2. docker 拉取指定架构的镜像 容器技术、虚拟机技术、模拟环境，各项技术上运行的程序对宿主机架构、指令集、宿主机内核的依赖情况虚拟机技术在宿主机上通过虚拟化技术模拟硬件设备，虚拟机运行在虚拟化层之上，仿佛自己运行在物理机上一般。每台虚拟机有自己的内核，有自己的操作系统在运行。通过模拟技术可以通过软件模拟出与底层不同架构的硬件，实际上有点像是在做翻译，比如在x86平台模拟ARM平台环境，再在这个模拟环境中运行ARM架构操作系统的虚拟机。比如这篇文章介绍了如何通过Qemu来实现在x86平台模拟运行ARM系统。ref：https://cloud.tencent.com/developer/article/1823083容器本质上是有特殊限制的进程，依赖的是宿主机内核，宿主机操作系统。因此尽管容器技术可以做到一处打包处处运行的便捷性，但是需要确保运行的镜像指令集与宿主机操作系统一致。因此我们需要使用与宿主机具有相同架构的镜像进行使用。关于虚拟机技术和容器技术的演进、差别的更多信息可以在kubernetes in action查看学习。 多架构支持docker镜像可以支持多架构，也就是说一个镜像可以有不同的架构、不同的操作系统的变体。当我们运行一个支持多架构的镜像时，docker会自动选择与宿主机的操作系统和架构契合的镜像变体。ref：https://docs.docker.com/desktop/multi-arch/ docker pull 命令行拉取指定架构我们也可以通过--platform 参数指定镜像的系统和架构，或者通过指定镜像的sha256值（摘要）来使用指定的镜像。方法一：使用--platform 参数：docker pull --platform linux/arm64 alpine:latest方法二：指定镜像的sha256值（摘要）首先列出所有支持的架构，然后指定sha256值（摘要）进行拉取。例如：# list all supported architectures (manifest):$ docker manifest inspect ckulka/multi-arch-example{ &quot;schemaVersion&quot;: 2, &quot;mediaType&quot;: &quot;application/vnd.docker.distribution.manifest.list.v2+json&quot;, &quot;manifests&quot;: [ { &quot;mediaType&quot;: &quot;application/vnd.docker.distribution.manifest.v2+json&quot;, &quot;size&quot;: 2200, &quot;digest&quot;: &quot;sha256:6eaeab9bf8270ce32fc974c36a15d0bac4fb6f6cd11a0736137c4248091b3646&quot;, &quot;platform&quot;: { &quot;architecture&quot;: &quot;amd64&quot;, &quot;os&quot;: &quot;linux&quot; } }, { &quot;mediaType&quot;: &quot;application/vnd.docker.distribution.manifest.v2+json&quot;, &quot;size&quot;: 2413, &quot;digest&quot;: &quot;sha256:f02e0fd2918a894ecd49d67b802c22082dc3c6424f6566e1753a83ba833b0993&quot;, &quot;platform&quot;: { &quot;architecture&quot;: &quot;arm&quot;, &quot;os&quot;: &quot;linux&quot;, &quot;variant&quot;: &quot;v5&quot; } },...# pull by digest, e.g. arm arch (pulled on linux machine):$ docker pull ckulka/multi-arch-example@sha256:f02e0fd2918a894ecd49d67b802c22082dc3c6424f6566e1753a83ba833b0993ref：https://stackoverflow.com/questions/60114854/pull-docker-image-for-different-architecture/60116565拉取之后，可以用docker inspect 验证一下镜像架构。3. vim块模式进行批量操作Ctrl + v 可以进入块选择模式，进入块模式后，可以进行批量插入、删除、替换等操作。 进入块模式，选取操作块 光标定位到要操作的地方 CTRL+v 进入“可视 块”模式 移动光标选取要操作的行和列 批量插入（按列插入） 进入块模式完成要块选取 shift + i （即大写 I ）进入输入模式 输入要批量插入的内容 按两次 ESC 键，完成插入 批量删除 在进入块模式完成选择后，按d进行删除 批量替换 进入块模式，完成需要操作的行的选取 按“:”，输入s/待替换内容/替换内容/g，回车 ，完成替换 4. Nginx proxy_pass通过proxy_pass可以设置代理转发，将匹配到指定URI的内容转发的代理的上游服务。location /some_dir/ { proxy_pass 上游服务;}而转发时的URI是否包含匹配的前缀，取决于配置上游服务时，是否有 /转发不带前缀:location /some_dir/ { proxy_pass http://some_server/;}如果配置时，以/ 结束，则按如下规则转发:http:// your_server/some_dir/ some_subdir/some_file -&amp;gt;http:// some_server/ some_subdir/some_file也就是, /some_dir/ 被 / 替换，将 /some_dir/some_subdir/some_file 变为 /some_subdir/some_file.转发带前缀:location /some_dir/ { proxy_pass http://some_server;}上游服务配置时不以/ 结束，则按如下规则替换:http:// your_server /some_dir/some_subdir/some_file -&amp;gt;http:// some_server /some_dir/some_subdir/some_file也就是, 按原URI传递，不进行替换变化。ref1:https://stackoverflow.com/questions/32542282/how-do-i-rewrite-urls-in-a-proxy-response-in-nginxref2: https://www.jianshu.com/p/b010c9302cd05. docker latest标签docker 的 latest 标签没有什么特殊之处，就是一个普通的标签，只是我们通常约定将最新版本的镜像打上 latest 标签。当实际上有 latest 标签的镜像可能根本不是最新的镜像，这只是一个约定，而没有机制上的保证。当我们进行操作时没有指定标签，docker 会自动加上 latest 标签进行操作。可以通过如下命令查看拉取的 latest 镜像的真正版本：docker image inspect the-image:latest | grep -i versionref: https://www.hi917.com/detail/105.html https://linux.cn/article-4772-1.html https://www.cnblogs.com/junejs/p/12686766.html#:~:text=latest是默认的标签,的标识，这是约定。6. mac chrome强制刷新 普通刷新：command ＋r 强制刷新：command＋shift＋r 删除cookie等：command＋shift＋del ，然后点击 清除数据，注意勾选选择要清楚的选项7. 命令行修改密钥密码$ ssh-keygen -pEnter file in which the key is (/Users/xxxx/.ssh/id_rsa): Enter old passphrase: Key has comment &#39;xxxxxxxxxxxxxx&#39;Enter new passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved with the new passphrase." }, { "title": "我的小仓库", "url": "/posts/efd7150a/", "categories": "default", "tags": "writing, tool", "date": "2022-02-24 23:09:55 +0800", "snippet": "搞了一个小仓库，用来放一些小游戏、小工具、小玩意儿。 简约文本冒险游戏 暗黑小屋 Dark Room 手绘风格在线画图工具 my excalidraw 小仓库暗黑小屋 Dark Room这是一款简约文本冒险游戏，经营自己的小屋，增加人口、收集物质，探索静谧的森林。。。在玩暗黑小屋这款小游戏之前，好像还没有玩过文本交互类型的游戏，之前倒是看到同学在步步高学习机上玩过类似的游戏。于是，发现暗黑小屋还挺有意思时，就在床边蹲着玩了好久。然后发现，还可以自己部署，就搞了一个放到小仓库。游戏的终点是发射火箭，去往星辰大海，支持多种语言。手绘风格在线画图工具excalidraw 是一个手绘风格在线画图工具，用了一下，还挺好用！手绘风格有点意思。然后发现，还可以自己部署！本来想着下个镜像部署在本地，但是m1芯片arm架构上运行不了amd64的镜像。于是就部署到vps上，顺手放到我的小仓库。excalidraw是一个开源项目，github仓库在excalidraw。" }, { "title": "我的头像", "url": "/posts/2f076b02/", "categories": "default", "tags": "writing, tool", "date": "2022-02-19 13:32:21 +0800", "snippet": "在看阮一峰的博客时，发现了一个根据输入的字符串生成头像的网站：multiavatar.com于是就生成了现在的头像：Hxysayhi再转换成各个尺寸和格式，妥妥的。呜呼呼呼呼～" }, { "title": "学海拾贝-20220214-20220219", "url": "/posts/1551f6df/", "categories": "Technology, notes", "tags": "note, 学海拾贝", "date": "2022-02-19 11:49:09 +0800", "snippet": "note-20220214-20220219 mac 输入法异常，出现两个输入候选框 kubectl 查看指定pod的最新n行日志 一个nginx配置实验网站 base64 编码后字符串长度变化 version 输出内容通过stderr 输出 强大的代码阅读工具source insight mac 输入法异常，出现两个输入候选框杀掉进程，然后重启进程啥的都不行，在v2ex 找到问题原因和解决方案： 原因：出现这个问题是因为输入文字时 launchpad 同步输入了搜索框，打开 launchpad 会发现搜索框里有一样的文字。 解决：打开 terminal，输入 killall Dock重启所有的 Dock 和 launchpad 即可解决亲测，在 terminal 输入 killall Dock 后，问题得到解决。查看指定pod的最新n行日志Tailing few lines from huge logs of kubectl logs -f# Display only the most recent 20 lines of output in pod nginxkubectl logs --tail=20 nginx# Show all logs from pod nginx written in the last hourkubectl logs --since=1h nginx一个nginx配置实验网站可以在网页上填写 nginx 配置文件，然后在线启动一个 nginx 实例。接着，你输入各种 curl 命令，与这个实例互动。https://nginx-playground.wizardzines.com/base64 编码后字符串长度变化https://www.ruanyifeng.com/blog/2008/06/base64.htmlBase64的编码转换方式。所谓Base64，就是说选出64个字符—-小写字母a-z、大写字母A-Z、数字0-9、符号”+”、”/”（再加上作为垫字的”=”，实际上是65个字符）—-作为一个基本字符集。然后，其他所有符号都转换成这个字符集中的字符。具体来说，转换方式可以分为四步。 第一步，将每三个字节作为一组，一共是24个二进制位。 第二步，将这24个二进制位分为四组，每个组有6个二进制位。 第三步，在每组前面加两个00，扩展成32个二进制位，即四个字节。 第四步，根据下表，得到扩展后的每个字节的对应符号，这就是Base64的编码值。 0　A　　17　R　　　34　i　　　51　z 1　B　　18　S　　　35　j　　　52　0 2　C　　19　T　　　36　k　　　53　1 3　D　　20　U　　　37　l　　　54　2 4　E　　21　V　　　38　m　　　55　3 5　F　　22　W　　　39　n　　　56　4 6　G　　23　X　　　40　o　　　57　5 7　H　　24　Y　　　41　p　　　58　6 8　I　　　25　Z　　　42　q　　　59　7 9　J　　26　a　　　43　r　　　60　8 10　K　　27　b　　　44　s　　　61　9 11　L　　28　c　　　45　t　　　62　+ 12　M　　29　d　　　46　u　　　63　/ 13　N　　30　e　　　47　v 14　O　　31　f　　　48　w 15　P　　32　g　　　49　x 16　Q　　33　h　　　50　y因为，Base64将三个字节转化成四个字节，因此Base64编码后的文本，会比原文本大出三分之一左右。version 输出内容通过stderr输出python2、java等在执行version输出时，是通过stderr输出的。实验： python2执行version输出$ python2 --versionPython 2.7.18 python2执行version输出，并将stdout重定向到 /dev/null$ python2 --version &amp;gt; /dev/nullPython 2.7.18 python2执行version输出，并将stderr重定向到 /dev/null$ python2 --version 2&amp;gt; /dev/null python3执行version输出$ python3 --version Python 3.8.9 python3执行version输出，并将stdout重定向到 /dev/null$ python3 --version &amp;gt; /dev/null python3执行version输出，并将stderr重定向到 /dev/null$ python3 --version 2&amp;gt; /dev/nullPython 3.8.9java -version 也是输出到stderr，测试版本是 1.8.0_101影响：对于获取stdout进行进一步处理的操作，就会出现获取不到数据的情况。比如通过创建子进程获取stdout并进行处理时，或者在命令行用管道进行级连处理时。对于创建子进程获取的情况，将stderr指定到stdout即可。对于命令行管道级连的方式，也一样：command 2&amp;gt;&amp;amp;1 | command2更进一步地，将stderr 信息通过stdout输出，不输出stdout：command 2&amp;gt;&amp;amp;1 &amp;gt;/dev/null | command2即将stderr重定向到stdout后，再把stdout重定向到/dev/null，并保持stderr指向原stdout不变。同理也可以将stdout重定向到指定的文件。参考： https://stackoverflow.com/questions/2342826/how-can-i-pipe-stderr-and-not-stdout https://stackoverflow.com/questions/16497317/piping-both-stdout-and-stderr-in-bash/37085215强大的代码阅读工具source insighthttps://www.sourceinsight.com/通过source insight能快速梳理代码结构，理清调用关系。具有以下关键功能： Helps to understand an existing code base. Quickly navigate function calls and callers. Find references to functions, variables, and more - almost instantly. See call graphs and class tree diagrams. Preview function and class definitions without having to open a file. See live references to variables and other declarations with Syntax Formatting. Powerful editing features, including code snippets, symbolic auto-completion, and smart-rename. Dynamic information panels work together to create a productive workflow." }, { "title": "在手机上创建、编辑并推送的第一条内容", "url": "/posts/2898f5e0/", "categories": "default", "tags": "writing, tool", "date": "2022-02-15 08:51:34 +0800", "snippet": "这是在手机上创建、编辑，并完成推送的第一条内容。这既是一个纪念，也是一个测试！在创建时，由于手机环境下，没有提前配置好随机字符串生成命令，导致固定链接生成失败，看来创建脚本可能还需要优化一下。ios端git 环境是 通过安装 ish shell，在虚拟Linux环境中安装git实现的。文档编辑是配合其他本地编辑工具完成。update：为了便于进行markdown文档编辑和预览，以及git commit的管理，使用 working copy进行管理和编辑。但是working copy的push功能需要付费，因此将working copy下管理的仓库挂载到ish中，利用ish中的git进行push。" }, { "title": "学海拾贝20220211", "url": "/posts/7af892d2/", "categories": "Technology, notes", "tags": "note, 学海拾贝", "date": "2022-02-14 09:39:53 +0800", "snippet": "20220124-20220214问题目录： shell script 中echo 变量时，换行丢失问题 vim 中粘贴代码，缩进错误 linux 文件拷贝，保留时间属性 umask 的作用 dlv 进行golang 调试传参数问题shell script 中echo 变量时，换行丢失问题问题描述在shell script中，将命令执行的结果复制给一个变量，供后续使用，命令执行的结果是多行输出，但是在后续对变量使用时，通过echo 输出变量时，没有换行。例如：TEST=`ls -l /`echo ${TEST}ls -l / 输出结果为：total 10drwxrwxr-x 40 root admin 1280 1 25 09:29 Applicationsdrwxr-xr-x 67 root wheel 2144 12 23 15:58 Librarydrwxr-xr-x@ 9 root wheel 288 12 8 07:39 Systemdrwxr-xr-x 5 root admin 160 12 8 07:39 Usersdrwxr-xr-x 3 root wheel 96 1 25 11:35 Volumesdrwxr-xr-x@ 38 root wheel 1216 12 8 07:39 bindrwxr-xr-x 2 root wheel 64 9 10 08:32 coresdr-xr-xr-x 4 root wheel 4762 12 20 21:10 devlrwxr-xr-x@ 1 root wheel 11 12 8 07:39 etc -&amp;gt; private/etclrwxr-xr-x 1 root wheel 25 12 20 21:12 home -&amp;gt; /System/Volumes/Data/homedrwxr-xr-x 3 root wheel 96 12 18 12:27 optdrwxr-xr-x 6 root wheel 192 12 8 07:39 privatedrwxr-xr-x@ 65 root wheel 2080 12 8 07:39 sbinlrwxr-xr-x@ 1 root wheel 11 12 8 07:39 tmp -&amp;gt; private/tmpdrwxr-xr-x@ 11 root wheel 352 12 8 07:39 usrlrwxr-xr-x@ 1 root wheel 11 12 8 07:39 var -&amp;gt; private/var赋值到变量再 echo 得到结果：total 10 drwxrwxr-x 40 root admin 1280 1 25 09:29 Applications drwxr-xr-x 67 root wheel 2144 12 23 15:58 Library drwxr-xr-x@ 9 root wheel 288 12 8 07:39 System drwxr-xr-x 5 root admin 160 12 8 07:39 Users drwxr-xr-x 3 root wheel 96 1 25 11:35 Volumes drwxr-xr-x@ 38 root wheel 1216 12 8 07:39 bin drwxr-xr-x 2 root wheel 64 9 10 08:32 cores dr-xr-xr-x 4 root wheel 4762 12 20 21:10 dev lrwxr-xr-x@ 1 root wheel 11 12 8 07:39 etc -&amp;gt; private/etc lrwxr-xr-x 1 root wheel 25 12 20 21:12 home -&amp;gt; /System/Volumes/Data/home drwxr-xr-x 3 root wheel 96 12 18 12:27 opt drwxr-xr-x 6 root wheel 192 12 8 07:39 private drwxr-xr-x@ 65 root wheel 2080 12 8 07:39 sbin lrwxr-xr-x@ 1 root wheel 11 12 8 07:39 tmp -&amp;gt; private/tmp drwxr-xr-x@ 11 root wheel 352 12 8 07:39 usr lrwxr-xr-x@ 1 root wheel 11 12 8 07:39 var -&amp;gt; private/var解决方案echo 时将变量用双引号包裹TEST=`ls -l /`echo &quot;${TEST}&quot;vim 中粘贴代码，缩进错误问题描述在vim粘贴代码时，代码原本已经有缩进，但粘贴时由于vim的自动缩进功能，导致出现多级缩进解决方案在命令行模式，设置进入paste模式：:set paste然后粘贴即可。取消paste模式：:set nopastelinux 文件拷贝，保留时间属性问题描述使用cp 命令拷贝文件后，拷贝后的文件更新时间为当前时间。但期望得到的结果是保留源文件的时间。解决方案cp -p /path/to/source/file /path/to/destination/file关于 cp 的参数：cp [options] source dest或cp [options] source... directory参数说明： a：此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容。其作用等于dpR参数组合。 d：复制时保留链接。这里所说的链接相当于 Windows 系统中的快捷方式。 f：覆盖已经存在的目标文件而不给出提示。 i：与 f 选项相反，在覆盖目标文件之前给出提示，要求用户确认是否覆盖，回答 y 时目标文件将被覆盖。 p：除复制文件的内容外，还把修改时间和访问权限也复制到新文件中。 r：若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。 l：不复制文件，只是生成链接文件。umask 的作用参考：https://www.cyberciti.biz/tips/understanding-linux-unix-umask-value-usage.html新的目录或文件的权限为base permissions - umask permissions目录的 base permissions 为 777文件的 base permissions 为 666 权限和值的对应关系：flag 标志位的表示方式| 权限值 | 二进制（rwx） | 权限 || — | — | — || 0 | 000 | no permissions || 1 | 001 | execute || 2 | 010 | write || 4 | 100 | read only | umask值和权限值对应权限关系： umask值 权限值 权限 0 （000） 7 （111） read, write and execute 1 （001） 6 （110） read and write 2 （010） 5 （101） read and execute 3 （011） 4 （100） read only 4 （100） 3 （011） write and execute 5 （101） 2 （010） write only 6 （110） 1 （001） execute only 7 （111） 0 （000） no permissions dlv 进行golang 调试传参数问题进行 golang调试时，希望对向待调试的程序进行传参，如何实现？使用 -- 告知 dlv 不要对之后的字符子串进行解析，而是进行原样传递。dlv --listen=:5432 exec /mypath/binary -- --config=config.toml ref: https://github.com/derekparker/delve/blob/master/Documentation/cli/getting_started.md#debugging-main-packageshttps://stackoverflow.com/questions/49923892/passing-arguments-to-executable-when-debugging-with-delve" }, { "title": "如何在nginx创建临时重定向和永久重定向", "url": "/posts/36358949/", "categories": "Technology, learn", "tags": "IT, note, nginx", "date": "2022-02-03 23:38:50 +0800", "snippet": "重定向的概念http重定向是将一个域名或者地址重新指向另一个域名或地址的方式。重定向的方式有多种，每一种对客户端而言都有些不同之处。其中两种最常见的重定向方式是临时重定向和永久重定向。临时重定向的返回码是 302。 临时重定向是用于一个url暂时需要通过一个临时站点进行服务的场景。当你的网站需要进行临时维护时，你可能就会希望在你进行维护期间，将访问重定向到另一个临时页码，在页面中提供临时服务或者通知用户网站正在进行维护，很快会恢复服务。永久重定向的返回码是 301。这个返回码希望告诉浏览器，应该放弃访问当前的url，并不再尝试访问当前URL。这种方式适用于当你的站点进行了永久性的迁移的情况，比如进行了域名更换等。你可以通过在nginx的配置中向server 配置块中添加如下内容来创建一个临时重定向：rewrite^/oldlocation$http://www.newdomain.com/newlocation redirect;类似地，可以添加如下内容来创建一个永久重定向：rewrite^/oldlocation$http://www.newdomain.com/newlocation permanent;就下来将会对nginx 中每种类型的重定向进行更加深入的解释，以及给出一些特别案例的用法。(待更新。。。。。)ref： How To Create Temporary and Permanent Redirects with Nginx" }, { "title": "jekyll post page 生成脚本", "url": "/posts/65e8b919/", "categories": "Technology, writing", "tags": "IT, jekyll, tool", "date": "2022-01-26 23:34:48 +0800", "snippet": "脚本功能： md 文件创建 md 头内容生成 生成随机短地址作为permalink，以便为每个page实现固定地址脚本内容：#!/usr/bin/env bashDIR=&quot;${0%/*}&quot;title=`echo $@ | sed &#39;s/[ ][ ]*/-/g&#39;`post_date=`date +&quot;%Y-%m-%d %T&quot;`post_name=&quot;`date &quot;+%Y-%m-%d&quot;`-${title}.markdown&quot;random_addr=`openssl rand -hex 8 | md5 | cut -c1-8`cat &amp;gt; ${DIR}/../_posts/${post_name} &amp;lt;&amp;lt; EOF---layout: posttitle: &quot;${title}&quot;description: &quot;&quot;date: ${post_date} +0800categories: defaultpermalink: /posts/${random_addr}/tags: [writing]---EOF使用方法：./new_post.sh &amp;lt;the new page name&amp;gt;" }, { "title": "containerd导入本地镜像的一个小坑", "url": "/posts/0e8b92e6/", "categories": "Technology, notes", "tags": "IT, note, container", "date": "2022-01-26 23:31:24 +0800", "snippet": "containerd 命令行工具为 ctr本地镜像导入命令：ctr image import &amp;lt;path/to/image/file&amp;gt;注意：当tar包没有tag信息时，导入之后，无报错，errno 为0，但是 通过 ctr images ls 查看却没有相关的镜像。这种情况，需要添加 --digests=true 来导入：ctr image import --digests=true &amp;lt;path/to/images/file&amp;gt;" }, { "title": "昔日博客传送门", "url": "/posts/76be18ed/", "categories": "default", "tags": "writing, blog", "date": "2022-01-26 22:56:09 +0800", "snippet": "建立一个传送门，传送到之前的博客" }, { "title": "jekyll静态blog部署 checklist", "url": "/posts/824d93f1/", "categories": "Technology, writing", "tags": "IT, note, jekyll", "date": "2022-01-23 12:33:55 +0800", "snippet": " 安装jekyll 1.1 安装ruby 为了避免版本冲突问题，使用rbenv进行安装（以ubuntu为例，参考https://gorails.com/setup/ubuntu/18.04） 安装rbenv cdgit clone https://github.com/rbenv/rbenv.git ~/.rbenvecho &#39;export PATH=&quot;$HOME/.rbenv/bin:$PATH&quot;&#39; &amp;gt;&amp;gt; ~/.bashrcecho &#39;eval &quot;$(rbenv init -)&quot;&#39; &amp;gt;&amp;gt; ~/.bashrcexec $SHELLgit clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-buildecho &#39;export PATH=&quot;$HOME/.rbenv/plugins/ruby-build/bin:$PATH&quot;&#39; &amp;gt;&amp;gt; ~/.bashrcexec $SHELL 安装ruby rbenv install 3.0.3rbenv global 3.0.3 检查安装是否符合预期 ruby -v 安装 Bundler gem install bundler 1.2 安装jekyll gem install jekyll bundler 创建blog project 方案一： 安装好ruby后，安装jekyll，并创建blog project： gem install bundler jekyll jekyll new myblog 方案二：直接选择自己喜欢的主题，从github将项目克隆到本地 vps上部署git仓库，配置hook实现自动部署blog能力(参考https://jekyllrb.com/docs/deployment/automated/) 3.1 创建git用户，并配置权限 创建 /var/www/myblog 目录，将用户属组配置为git用户 3.2 创建git仓库 以git用户登录vps cd mkdir myrepo.git cd myrepo.git git --bare init 在 myrepo.git 中创建 hooks/post-receive 文件，内容如下： # Install Ruby Gems to ~/gems export PATH=&quot;$HOME/.rbenv/bin:$PATH&quot; eval &quot;$(rbenv init -)&quot; export PATH=&quot;$HOME/.rbenv/plugins/ruby-build/bin:$PATH&quot; export GEM_HOME=$HOME/gems export PATH=$GEM_HOME/bin:$PATH TMP_GIT_CLONE=$HOME/tmp/jekyll-blog GEMFILE=$TMP_GIT_CLONE/Gemfile PUBLIC_WWW=/var/www/myblog git clone $GIT_DIR $TMP_GIT_CLONE BUNDLE_GEMFILE=$GEMFILE bundle install BUNDLE_GEMFILE=$GEMFILE bundle exec jekyll build -s $TMP_GIT_CLONE -d $PUBLIC_WWW rm -Rf $TMP_GIT_CLONE exit 3.3 本地blog project绑定vps git 仓库 cd myblog git init git remote add deploy git@remote-address:/path/to/myrepo.git git push --set-upstream deploy master 后续push时将会触发vps git hook进行自动部署 vps上部署nginx 4.1 部署nginx 4.2 根据前面步骤中 PUBLIC_WWW 的值，配置nginx 4.3 安装域名证书（可通过certbot完成） " }, { "title": "Welcome to Jekyll!", "url": "/posts/welcome-to-jekyll/", "categories": "default", "tags": "", "date": "2022-01-20 15:33:55 +0800", "snippet": "You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.Jekyll requires blog post files to be named according to the following format:YEAR-MONTH-DAY-title.MARKUPWhere YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and MARKUP is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.Jekyll also offers powerful support for code snippets:def print_hi(name) puts &quot;Hi, #{name}&quot;endprint_hi(&#39;Tom&#39;)#=&amp;gt; prints &#39;Hi, Tom&#39; to STDOUT.Check out the Jekyll docs for more info on how to get the most out of Jekyll. File all bugs/feature requests at Jekyll’s GitHub repo. If you have questions, you can ask them on Jekyll Talk." } ]
